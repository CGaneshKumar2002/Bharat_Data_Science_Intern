# Titanic Survival Prediction
This project focuses on predicting the survival outcomes of passengers aboard the Titanic using two different machine learning algorithms: Naive Bayes and K-Nearest Neighbors (KNN). The project involves implementing both algorithms from scratch and comparing their accuracies.

# Dataset
The dataset used in this project is the famous "Titanic: Machine Learning from Disaster" dataset, which contains information about passengers aboard the Titanic, including their survival status. The dataset consists of various features such as age, sex, passenger class, and fare. The goal is to build a model that can predict whether a passenger survived or not based on these features.

# Algorithms
## Naive Bayes
The Naive Bayes algorithm is a probabilistic classifier based on Bayes' theorem with an assumption of independence between features. In this project, Naive Bayes is used to predict the survival outcomes of the Titanic passengers. The algorithm calculates the probability of a passenger surviving or not given their feature values and selects the class with the highest probability as the prediction.

## K-Nearest Neighbors (KNN)
K-Nearest Neighbors (KNN) is a non-parametric algorithm used for classification. In this project, KNN is implemented to predict the survival outcomes of the Titanic passengers. The algorithm works by finding the K nearest neighbors of a given test sample based on a distance metric (e.g., Euclidean distance) and assigns the class label based on the majority vote of the K neighbors.

# Implementation
The Naive Bayes and KNN algorithms have been implemented from scratch in this project. The implementation involves writing the necessary functions to train the models and make predictions.

The following steps were performed for each algorithm:

1. Data preprocessing: The Titanic dataset was preprocessed to handle missing values, categorical features, and feature scaling if required.

2. Model training: The training data was used to train the Naive Bayes and KNN models. For Naive Bayes, the algorithm estimates the class probabilities and conditional probabilities of feature values. For KNN, the algorithm stores the training data points and their corresponding class labels.

3. Model prediction: The trained models were used to make predictions on the test data. For Naive Bayes, the probability calculations were performed using the trained parameters, and the class with the highest probability was assigned as the prediction. For KNN, the algorithm calculated the distances between the test sample and the training data points, selected the K nearest neighbors, and assigned the class based on majority voting.

4. Model evaluation: The accuracies of both models were calculated by comparing the predicted survival outcomes with the actual survival labels from the test data. The accuracy metric was used to measure the performance of the models.

# Results
The accuracies of the Naive Bayes and KNN models were compared to assess their predictive performance on the Titanic survival prediction task. The accuracy metric provides an indication of how well the models were able to classify the passengers correctly.
The accuracies are provided in the notebook file.
The comparison of accuracies helps in understanding the strengths and weaknesses of each algorithm for the given task.

# Conclusion
In this project, I implemented Naive Bayes and KNN algorithms from scratch for predicting the survival outcomes of Titanic passengers. By comparing the accuracies of both models, their effectiveness can be assessed in solving the task. The README provides an overview of the project, the dataset, the algorithms used, the implementation steps, and the results obtained.

This project can serve as a starting point for further exploration and improvement of the prediction models. It also demonstrates the importance of evaluating multiple algorithms to identify the most suitable approach for a given task.
